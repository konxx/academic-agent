import streamlit as st
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Dict, Any

# --- æ ¸å¿ƒæ¨¡å—å¯¼å…¥ ---
from core.qdrant import qdrant_manager
from core.clustering import clustering_service
from utils.logger import logger

st.set_page_config(page_title="Knowledge Clustering", page_icon="ğŸ§¬", layout="wide")

st.title("ğŸ§¬ Knowledge Clustering")
st.caption("è‡ªåŠ¨å‘ç°è®ºæ–‡ä¸»é¢˜ + äº¤äº’å¼ä¸»é¢˜ç®¡ç†")

# ==========================================
# Session State åˆå§‹åŒ–
# ==========================================
if "clustering_result" not in st.session_state:
    st.session_state.clustering_result = None

if "cluster_names" not in st.session_state:
    st.session_state.cluster_names = {}

if "current_labels" not in st.session_state:
    st.session_state.current_labels = None


# ==========================================
# è¾…åŠ©å‡½æ•°
# ==========================================
def create_scatter_plot(viz_data: Dict, n_dims: int = 2) -> go.Figure:
    """åˆ›å»ºæ•£ç‚¹å›¾å¯è§†åŒ–"""
    if n_dims == 2:
        fig = px.scatter(
            x=viz_data["x"],
            y=viz_data["y"],
            color=viz_data["cluster_names"],
            hover_name=viz_data["titles"],
            title="ğŸ“Š è®ºæ–‡èšç±»å¯è§†åŒ– (2D)",
            labels={"x": "PC1", "y": "PC2", "color": "ä¸»é¢˜"},
        )
    else:
        fig = px.scatter_3d(
            x=viz_data["x"],
            y=viz_data["y"],
            z=viz_data["z"],
            color=viz_data["cluster_names"],
            hover_name=viz_data["titles"],
            title="ğŸ“Š è®ºæ–‡èšç±»å¯è§†åŒ– (3D)",
            labels={"x": "PC1", "y": "PC2", "z": "PC3", "color": "ä¸»é¢˜"},
        )
    
    fig.update_layout(
        height=600,
        legend=dict(orientation="h", yanchor="bottom", y=-0.2)
    )
    return fig


# ==========================================
# ä¸»ç•Œé¢ï¼šè‡ªåŠ¨èšç±»
# ==========================================
st.subheader("1. é…ç½®èšç±»å‚æ•°")

col1, col2 = st.columns(2)

with col1:
    clustering_method = st.selectbox(
        "èšç±»ç®—æ³•",
        ["K-Means (æ¨è)", "DBSCAN (è‡ªåŠ¨å‘ç°)"],
        help="K-Means å¯æŒ‡å®šä¸»é¢˜æ•°é‡ï¼Œé€‚åˆå¤§è®ºæ–‡åº“ï¼›DBSCAN è‡ªåŠ¨å‘ç°ç°‡ä½†å¯èƒ½ä¸å‡åŒ€"
    )

with col2:
    pca_components = st.slider(
        "PCA é™ç»´ç»´åº¦",
        10, 100, 50,
        help="èšç±»å‰å°†å‘é‡é™åˆ°å¤šå°‘ç»´ï¼Ÿè¾ƒä½ç»´åº¦å¯èƒ½å‘ç°æ›´ç²—ç²’åº¦çš„ä¸»é¢˜"
    )

st.markdown("### ğŸ“Š ç®—æ³•å‚æ•°")

if "K-Means" in clustering_method:
    col_a, col_b = st.columns(2)
    with col_a:
        n_clusters = st.slider(
            "ä¸»é¢˜ç°‡æ•°é‡",
            3, 30, 10,
            help="å°†è®ºæ–‡åˆ†ä¸ºå¤šå°‘ä¸ªä¸»é¢˜ï¼Ÿå»ºè®®ï¼š50ç¯‡â†’5ç°‡ï¼Œ200ç¯‡â†’10ç°‡ï¼Œ500ç¯‡â†’15ç°‡"
        )
    with col_b:
        st.info("ğŸ’¡ å»ºè®®æ ¹æ®è®ºæ–‡åº“å¤§å°è®¾ç½® **8-15 ä¸ª**ä¸»é¢˜ç°‡")
else:
    col_a, col_b, col_c = st.columns(3)
    with col_a:
        eps_value = st.slider(
            "é‚»åŸŸåŠå¾„ (eps)",
            0.1, 2.0, 0.5, 0.05,
            help="å€¼è¶Šå°ï¼Œç°‡è¶Šå¤šè¶Šç»†ï¼›å€¼è¶Šå¤§ï¼Œç°‡è¶Šå°‘è¶Šç²—"
        )
    with col_b:
        min_samples = st.slider(
            "æœ€å°æ ·æœ¬æ•°",
            2, 10, 3,
            help="å½¢æˆç°‡æ‰€éœ€çš„æœ€å°é‚»å±…æ•°"
        )
    with col_c:
        st.warning("âš ï¸ DBSCAN å¯¹å‚æ•°æ•æ„Ÿï¼Œå¦‚ç»“æœä¸å‡åŒ€è¯·è°ƒæ•´ eps")

generate_labels = st.checkbox(
    "ğŸ·ï¸ ä½¿ç”¨ AI ç”Ÿæˆä¸»é¢˜æ ‡ç­¾",
    value=True,
    help="è°ƒç”¨ LLM ä¸ºæ¯ä¸ªç°‡ç”Ÿæˆæè¿°æ€§æ ‡ç­¾"
)

st.divider()

if st.button("ğŸš€ å¼€å§‹è‡ªåŠ¨èšç±»", type="primary"):
    with st.spinner("æ­£åœ¨åˆ†æè®ºæ–‡åº“..."):
        try:
            progress = st.progress(0)
            status = st.empty()
            
            status.text("ğŸ“š æ­£åœ¨è·å–è®ºæ–‡æ•°æ®...")
            papers = clustering_service.fetch_all_papers(limit=500)
            progress.progress(20)
            
            if len(papers) < 3:
                st.warning("âš ï¸ è®ºæ–‡åº“ä¸­è®ºæ–‡æ•°é‡ä¸è¶³ï¼Œè¯·å…ˆä¸Šä¼ æ›´å¤šè®ºæ–‡ã€‚")
            else:
                status.text("ğŸ“‰ æ­£åœ¨è¿›è¡Œé™ç»´...")
                vectors = np.array([p["vector"] for p in papers])
                reduced = clustering_service.reduce_dimensions(vectors, n_components=pca_components)
                progress.progress(40)
                
                status.text("ğŸ§¬ æ­£åœ¨æ‰§è¡Œèšç±»...")
                if "K-Means" in clustering_method:
                    labels, n_found = clustering_service.auto_cluster_kmeans(reduced, n_clusters)
                else:
                    labels, n_found = clustering_service.auto_cluster_hdbscan(
                        reduced,
                        min_cluster_size=min_samples, 
                        min_samples=min_samples,
                        eps=eps_value
                    )
                progress.progress(60)
                
                if generate_labels:
                    status.text("ğŸ·ï¸ æ­£åœ¨ç”Ÿæˆä¸»é¢˜æ ‡ç­¾...")
                    grouped = clustering_service.group_papers_by_cluster(papers, labels)
                    cluster_names = clustering_service.generate_cluster_labels(grouped)
                else:
                    cluster_names = {i: f"Cluster {i}" for i in set(labels)}
                progress.progress(80)
                
                status.text("ğŸ“Š æ­£åœ¨å‡†å¤‡å¯è§†åŒ–...")
                viz_data = clustering_service.prepare_visualization_data(
                    papers, labels, cluster_names, n_dims=3
                )
                progress.progress(100)
                
                st.session_state.clustering_result = {
                    "papers": papers,
                    "vectors": vectors,
                    "reduced": reduced,
                    "labels": labels,
                    "cluster_names": cluster_names,
                    "viz_data": viz_data
                }
                st.session_state.current_labels = labels
                st.session_state.cluster_names = cluster_names
                
                progress.empty()
                status.empty()
                
                st.success(f"âœ… èšç±»å®Œæˆï¼å‘ç° {n_found} ä¸ªä¸»é¢˜ç°‡ï¼Œå…± {len(papers)} ç¯‡è®ºæ–‡")
                st.rerun()
                
        except Exception as e:
            st.error(f"âŒ èšç±»å¤±è´¥: {str(e)}")
            logger.error(f"Clustering Error: {e}")

# --- æ˜¾ç¤ºèšç±»ç»“æœ ---
if st.session_state.clustering_result:
    result = st.session_state.clustering_result
    papers = result["papers"]
    labels = st.session_state.current_labels
    cluster_names = st.session_state.cluster_names
    
    st.divider()
    st.subheader("2. èšç±»ç»“æœå¯è§†åŒ–")
    
    viz_col1, viz_col2 = st.columns([2, 1])
    
    with viz_col1:
        viz_dims = st.radio("å¯è§†åŒ–ç»´åº¦", [2, 3], horizontal=True)
        viz_data = clustering_service.prepare_visualization_data(
            papers, labels, cluster_names, n_dims=viz_dims
        )
        fig = create_scatter_plot(viz_data, viz_dims)
        st.plotly_chart(fig, use_container_width=True)
    
    with viz_col2:
        st.markdown("### ğŸ“Š ä¸»é¢˜ç»Ÿè®¡")
        grouped = clustering_service.group_papers_by_cluster(papers, labels)
        
        for cluster_id in sorted(grouped.keys()):
            if cluster_id == -1:
                continue
            cluster_papers = grouped[cluster_id]
            name = cluster_names.get(cluster_id, f"Cluster {cluster_id}")
            st.metric(
                label=f"ğŸ·ï¸ {name}",
                value=f"{len(cluster_papers)} ç¯‡"
            )
    
    st.divider()
    st.subheader("3. äº¤äº’å¼ç°‡ç®¡ç†")
    
    manage_col1, manage_col2 = st.columns(2)
    
    with manage_col1:
        st.markdown("#### ğŸ”— åˆå¹¶ç°‡")
        cluster_ids = [k for k in grouped.keys() if k != -1]
        clusters_to_merge = st.multiselect(
            "é€‰æ‹©è¦åˆå¹¶çš„ç°‡",
            options=cluster_ids,
            format_func=lambda x: f"{cluster_names.get(x, f'Cluster {x}')} ({len(grouped.get(x, []))}ç¯‡)"
        )
        
        if st.button("åˆå¹¶é€‰ä¸­çš„ç°‡") and len(clusters_to_merge) >= 2:
            new_labels = clustering_service.merge_clusters(labels, clusters_to_merge)
            st.session_state.current_labels = new_labels
            target = min(clusters_to_merge)
            merged_name = " + ".join([cluster_names.get(c, f"C{c}") for c in clusters_to_merge])
            st.session_state.cluster_names[target] = merged_name
            st.success("âœ… å·²åˆå¹¶ç°‡")
            st.rerun()
    
    with manage_col2:
        st.markdown("#### âœ‚ï¸ æ‹†åˆ†ç°‡")
        cluster_to_split = st.selectbox(
            "é€‰æ‹©è¦æ‹†åˆ†çš„ç°‡",
            options=cluster_ids,
            format_func=lambda x: f"{cluster_names.get(x, f'Cluster {x}')} ({len(grouped.get(x, []))}ç¯‡)"
        )
        n_splits = st.slider("æ‹†åˆ†æ•°é‡", 2, 5, 2)
        
        if st.button("æ‹†åˆ†è¯¥ç°‡"):
            new_labels = clustering_service.split_cluster(
                result["reduced"],
                labels,
                cluster_to_split,
                n_splits
            )
            st.session_state.current_labels = new_labels
            st.success("âœ… å·²æ‹†åˆ†ç°‡")
            st.rerun()
    
    st.divider()
    st.markdown("#### âœï¸ é‡å‘½åç°‡")
    
    rename_col1, rename_col2 = st.columns([1, 2])
    with rename_col1:
        cluster_to_rename = st.selectbox(
            "é€‰æ‹©ç°‡",
            options=cluster_ids,
            format_func=lambda x: f"{cluster_names.get(x, f'Cluster {x}')}",
            key="rename_cluster"
        )
    
    current_name = cluster_names.get(cluster_to_rename, "")
    
    with rename_col2:
        new_name = st.text_input(
            "æ–°åç§°",
            value=current_name,
            key=f"rename_input_{cluster_to_rename}"
        )
        if st.button("æ›´æ–°åç§°"):
            st.session_state.cluster_names[cluster_to_rename] = new_name
            st.success("âœ… å·²æ›´æ–°ç°‡åç§°")
            st.rerun()
    
    st.divider()
    st.subheader("4. è®ºæ–‡è¯¦æƒ…")
    
    selected_cluster = st.selectbox(
        "é€‰æ‹©ä¸»é¢˜æŸ¥çœ‹è®ºæ–‡",
        options=cluster_ids,
        format_func=lambda x: f"{cluster_names.get(x, f'Cluster {x}')} ({len(grouped.get(x, []))}ç¯‡)"
    )
    
    if selected_cluster is not None:
        cluster_papers = grouped.get(selected_cluster, [])
        
        for paper in cluster_papers:
            meta = paper["metadata"]
            title = meta.get("title", "Unknown Title")
            venue = meta.get("venue", "Unknown")
            year = meta.get("year", "N/A")
            authors = meta.get("authors", [])
            
            if isinstance(authors, list):
                authors_str = ", ".join(authors[:3]) + ("..." if len(authors) > 3 else "")
            else:
                authors_str = str(authors)
            
            with st.container(border=True):
                st.markdown(f"### ğŸ“„ {title}")
                st.caption(f"ğŸ‘¤ {authors_str} | ğŸ›ï¸ {venue} ({year})")
                
                if abstract := meta.get("abstract"):
                    with st.expander("æŸ¥çœ‹æ‘˜è¦"):
                        st.write(abstract)