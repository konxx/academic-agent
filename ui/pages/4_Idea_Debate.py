import streamlit as st
import time
import json
import re
from typing import List, Dict, Optional
from dataclasses import dataclass
import plotly.graph_objects as go
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

# --- æ ¸å¿ƒæ¨¡å—å¯¼å…¥ ---
from config.settings import settings
from core.llm import get_agent_llm, get_critic_llm

try:
    from langchain_openai import ChatOpenAI
except ImportError:
    pass

st.set_page_config(page_title="Idea Debate Arena", page_icon="âš”ï¸", layout="wide")

st.title("âš”ï¸ è®ºæ–‡æƒ³æ³•è¾©è®º")
st.caption("è¾“å…¥ç ”ç©¶æƒ³æ³•ï¼Œé€šè¿‡ AI å¯¹æŠ—æ€§è¾©è®ºæ‰“ç£¨å‡ºæ›´ä¸¥è°¨ã€æ›´æœ‰åˆ›æ–°æ€§çš„è®ºæ–‡æ–¹æ¡ˆ")

# ==========================================
# æ•°æ®ç»“æ„å®šä¹‰
# ==========================================
@dataclass
class CriticScore:
    novelty: int = 0
    soundness: int = 0
    significance: int = 0
    experiments: int = 0
    overall: int = 0
    verdict: str = "REVISE"
    key_issues: List[str] = None
    focus_next: str = ""
    
    def __post_init__(self):
        if self.key_issues is None:
            self.key_issues = []

@dataclass  
class DebateRound:
    round_num: int
    builder_response: str
    critic_response: str
    scores: CriticScore
    timestamp: float = 0.0

BUILDER_SYSTEM_PROMPT = """ä½ æ˜¯ **è®ºæ–‡æ„å»ºè€… (Builder)**ï¼ŒèŒè´£æ˜¯å°†ç”¨æˆ·çš„ç ”ç©¶æƒ³æ³•å‘å±•æˆä¸€ä¸ªä¸¥è°¨ã€å¯è¡Œçš„å­¦æœ¯è®ºæ–‡æ–¹æ¡ˆã€‚

## ç ”ç©¶æƒ³æ³• (æ ¸å¿ƒä¸å¯åç¦»)
{goal}

## è¾“å‡ºæ ¼å¼è¦æ±‚ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)
è¯·æŒ‰ä»¥ä¸‹å­¦æœ¯è®ºæ–‡ç»“æ„è¾“å‡ºä½ çš„æ–¹æ¡ˆï¼š

### ğŸ”¬ ç ”ç©¶é—®é¢˜ (Research Question)
- æ˜ç¡®è¦è§£å†³çš„æ ¸å¿ƒç§‘å­¦é—®é¢˜
- ç°æœ‰æ–¹æ³•çš„ä¸è¶³ä¹‹å¤„ (Research Gap)

### ğŸ’¡ ä¸»è¦åˆ›æ–°ç‚¹ (Contributions)
- [åˆ—å‡º 2-3 ä¸ªæ˜ç¡®çš„å­¦æœ¯è´¡çŒ®]
- è¯´æ˜ä¸ç°æœ‰å·¥ä½œçš„å·®å¼‚

### ï¿½ æ–¹æ³•è®º (Methodology)
- æå‡ºçš„æ–¹æ³•/æ¨¡å‹/æ¡†æ¶
- å…³é”®æŠ€æœ¯ç»†èŠ‚
- ç†è®ºä¾æ®æˆ–åŸç†

### ğŸ§ª å®éªŒè®¾è®¡ (Experiments)
- æ•°æ®é›†é€‰æ‹©åŠç†ç”±
- åŸºçº¿å¯¹æ¯”æ–¹æ³• (Baselines)
- è¯„ä¼°æŒ‡æ ‡ (Metrics)
- æ¶ˆèå®éªŒè®¡åˆ’ (Ablation Study)

### âš ï¸ æ½œåœ¨å±€é™æ€§ (Limitations)
- ä¸»åŠ¨è¯†åˆ«å¯èƒ½çš„å¼±ç‚¹
- åº”å¯¹æˆ–ç¼“è§£ç­–ç•¥

## è§„åˆ™
1. **é¦–è½®**ï¼šæå‡ºå®Œæ•´çš„è®ºæ–‡ç ”ç©¶æ–¹æ¡ˆ
2. **åç»­è½®**ï¼šé’ˆå¯¹ Critic çš„å­¦æœ¯æ‰¹è¯„è¿›è¡Œå®šå‘æ”¹è¿›
3. ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ï¼Œå¼•ç”¨ç›¸å…³å·¥ä½œæ—¶è¦å…·ä½“
4. ç”¨ä¸­æ–‡å›å¤"""

CRITIC_SYSTEM_PROMPT = """ä½ æ˜¯ **å­¦æœ¯å®¡ç¨¿äºº (Critic)**ï¼ŒèŒè´£æ˜¯ä»¥é¡¶ä¼š/é¡¶åˆŠå®¡ç¨¿äººçš„æ ‡å‡†ä¸¥æ ¼è¯„ä¼°è®ºæ–‡æ–¹æ¡ˆã€‚

## è¯„ä¼°ç»´åº¦ (å¯¹æ ‡é¡¶ä¼šå®¡ç¨¿æ ‡å‡†)
1. **novelty (åˆ›æ–°æ€§)**: ç ”ç©¶é—®é¢˜æ˜¯å¦æ–°é¢–ï¼Ÿæ–¹æ³•æ˜¯å¦æœ‰åŸåˆ›æ€§ï¼Ÿæ˜¯å¦åªæ˜¯ç®€å•çš„ç»„åˆï¼Ÿ
2. **soundness (ç†è®ºä¸¥è°¨æ€§)**: æ–¹æ³•è®ºæ˜¯å¦æœ‰ç†è®ºæ”¯æ’‘ï¼Ÿé€»è¾‘æ˜¯å¦å®Œæ•´ï¼Ÿæœ‰æ— æ˜æ˜¾æ¼æ´ï¼Ÿ
3. **significance (é‡è¦æ€§)**: ç ”ç©¶é—®é¢˜æ˜¯å¦é‡è¦ï¼Ÿèƒ½å¦æ¨åŠ¨é¢†åŸŸå‘å±•ï¼Ÿ
4. **experiments (å®éªŒè®¾è®¡)**: å®éªŒæ˜¯å¦å……åˆ†ï¼Ÿbaselinesé€‰æ‹©æ˜¯å¦åˆç†ï¼Ÿè¯„ä¼°æŒ‡æ ‡æ˜¯å¦æ°å½“ï¼Ÿ

## è¾“å‡ºæ ¼å¼ (å¿…é¡»è¾“å‡ºæœ‰æ•ˆJSON)
```json
{
  "scores": {
    "novelty": <1-10åˆ†>,
    "soundness": <1-10åˆ†>,
    "significance": <1-10åˆ†>,
    "experiments": <1-10åˆ†>
  },
  "overall": <1-10åˆ†ï¼Œç»¼åˆè¯„åˆ†>,
  "verdict": "<PASS æˆ– REVISE>",
  "key_issues": ["å…·ä½“å­¦æœ¯é—®é¢˜1", "å…·ä½“å­¦æœ¯é—®é¢˜2"],
  "focus_next": "ä¸‹ä¸€è½®åº”é‡ç‚¹æ”¹è¿›çš„å­¦æœ¯é—®é¢˜"
}
```

## è¯„å®¡æ ‡å‡†
- **Strong Accept (9-10)**: é‡å¤§åˆ›æ–°ï¼Œæ–¹æ³•ä¸¥è°¨ï¼Œå®éªŒå……åˆ†
- **Accept (7-8)**: æœ‰åˆ›æ–°ç‚¹ï¼Œæ–¹æ³•åˆç†ï¼Œå®éªŒåŸºæœ¬å®Œæ•´
- **Borderline (5-6)**: åˆ›æ–°æœ‰é™ï¼Œå­˜åœ¨ä¸€äº›é—®é¢˜ä½†å¯ä¿®æ”¹
- **Reject (1-4)**: åˆ›æ–°ä¸è¶³æˆ–å­˜åœ¨ä¸¥é‡é—®é¢˜

## é€šè¿‡æ ‡å‡†
- å½“ overall >= 8 ä¸”æ—  key_issues æ—¶ï¼Œverdict = "PASS" (ç›¸å½“äº Accept)
- å¦åˆ™ verdict = "REVISE"

## è§„åˆ™
1. åƒçœŸå®å®¡ç¨¿äººä¸€æ ·æå‡ºå»ºè®¾æ€§æ‰¹è¯„
2. æŒ‡å‡ºä¸ç°æœ‰å·¥ä½œçš„å¯èƒ½é‡å  (å¦‚æœ‰)
3. è´¨ç–‘å®éªŒè®¾è®¡çš„åˆç†æ€§
4. æ‰¿è®¤ Builder çš„æ”¹è¿›è¿›æ­¥
5. ç”¨ä¸­æ–‡å¡«å†™ key_issues å’Œ focus_next"""

# ==========================================
# è¾…åŠ©å‡½æ•°
# ==========================================
def get_model_instance(model_name: str, temperature: float):
    """æ™ºèƒ½æ¨¡å‹è·¯ç”±"""
    model_name_lower = model_name.lower()
    if "deepseek" in model_name_lower:
        llm = get_agent_llm(temperature=temperature)
        llm.model_name = model_name
        return llm
    elif "qwen" in model_name_lower:
        llm = get_critic_llm(temperature=temperature)
        llm.model_name = model_name
        llm.temperature = temperature
        return llm
    else:
        return ChatOpenAI(
            model=model_name,
            temperature=temperature,
            api_key=settings.OPENAI_API_KEY if hasattr(settings, 'OPENAI_API_KEY') else None
        )

def parse_critic_response(response: str) -> CriticScore:
    """è§£æ Critic çš„ JSON å“åº”"""
    try:
        # å°è¯•æå– JSON å—
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å°è¯•ç›´æ¥è§£æ
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                raise ValueError("No JSON found")
        
        data = json.loads(json_str)
        scores = data.get("scores", {})
        
        return CriticScore(
            novelty=scores.get("novelty", 5),
            soundness=scores.get("soundness", 5),
            significance=scores.get("significance", 5),
            experiments=scores.get("experiments", 5),
            overall=data.get("overall", 5),
            verdict=data.get("verdict", "REVISE"),
            key_issues=data.get("key_issues", []),
            focus_next=data.get("focus_next", "")
        )
    except Exception as e:
        # Fallback: å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤è¯„åˆ†
        return CriticScore(
            overall=5,
            verdict="REVISE",
            key_issues=["JSONè§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥Criticè¾“å‡ºæ ¼å¼"],
            focus_next="ç»§ç»­æ”¹è¿›æ–¹æ¡ˆ"
        )

def create_score_chart(rounds: List[DebateRound]) -> go.Figure:
    """åˆ›å»ºè¯„åˆ†è¶‹åŠ¿å›¾"""
    if not rounds:
        return None
    
    round_nums = [r.round_num for r in rounds]
    overall_scores = [r.scores.overall for r in rounds]
    novelty = [r.scores.novelty for r in rounds]
    soundness = [r.scores.soundness for r in rounds]
    significance = [r.scores.significance for r in rounds]
    experiments = [r.scores.experiments for r in rounds]
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=round_nums, y=overall_scores,
        mode='lines+markers',
        name='ç»¼åˆè¯„åˆ†',
        line=dict(color='#FF6B6B', width=3),
        marker=dict(size=10)
    ))
    
    fig.add_trace(go.Scatter(
        x=round_nums, y=novelty,
        mode='lines+markers',
        name='åˆ›æ–°æ€§',
        line=dict(color='#4ECDC4', width=2, dash='dot')
    ))
    
    fig.add_trace(go.Scatter(
        x=round_nums, y=soundness,
        mode='lines+markers', 
        name='ä¸¥è°¨æ€§',
        line=dict(color='#45B7D1', width=2, dash='dot')
    ))
    
    fig.add_trace(go.Scatter(
        x=round_nums, y=significance,
        mode='lines+markers',
        name='é‡è¦æ€§',
        line=dict(color='#96CEB4', width=2, dash='dot')
    ))
    
    fig.add_trace(go.Scatter(
        x=round_nums, y=experiments,
        mode='lines+markers',
        name='å®éªŒè®¾è®¡',
        line=dict(color='#FFEAA7', width=2, dash='dot')
    ))
    
    # æ·»åŠ é€šè¿‡çº¿
    fig.add_hline(y=8, line_dash="dash", line_color="green", 
                  annotation_text="é€šè¿‡çº¿ (8åˆ†)")
    
    fig.update_layout(
        title="ğŸ“ˆ è¯„åˆ†è¶‹åŠ¿",
        xaxis_title="è½®æ¬¡",
        yaxis_title="è¯„åˆ†",
        yaxis=dict(range=[0, 10.5]),
        height=300,
        margin=dict(l=20, r=20, t=40, b=20),
        legend=dict(orientation="h", yanchor="bottom", y=-0.3)
    )
    
    return fig

def generate_summary(rounds: List[DebateRound], goal: str) -> str:
    """ç”Ÿæˆè¾©è®ºæ€»ç»“"""
    if not rounds:
        return ""
    
    final_round = rounds[-1]
    total_rounds = len(rounds)
    final_score = final_round.scores.overall
    status = "âœ… æ–¹æ¡ˆé€šè¿‡" if final_round.scores.verdict == "PASS" else "â¸ï¸ è¾¾åˆ°è½®æ¬¡ä¸Šé™"
    
    # è®¡ç®—è¿›æ­¥å¹…åº¦
    if len(rounds) > 1:
        improvement = final_score - rounds[0].scores.overall
        improvement_text = f"+{improvement}" if improvement > 0 else str(improvement)
    else:
        improvement_text = "N/A"
    
    summary = f"""
## ğŸ“‹ è¾©è®ºæ€»ç»“

| æŒ‡æ ‡ | å€¼ |
|-----|-----|
| æ ¸å¿ƒç›®æ ‡ | {goal[:50]}... |
| æ€»è½®æ¬¡ | {total_rounds} |
| æœ€ç»ˆè¯„åˆ† | {final_score}/10 |
| è¯„åˆ†å˜åŒ– | {improvement_text} |
| æœ€ç»ˆçŠ¶æ€ | {status} |

### æœ€ç»ˆæ–¹æ¡ˆæ‘˜è¦
{final_round.builder_response[:500]}...
"""
    return summary

def export_to_markdown(rounds: List[DebateRound], goal: str) -> str:
    """å¯¼å‡ºè¾©è®ºè®°å½•ä¸º Markdown"""
    md = f"# è¾©è®ºè®°å½•\n\n## æ ¸å¿ƒç›®æ ‡\n{goal}\n\n---\n\n"
    
    for r in rounds:
        md += f"## ç¬¬ {r.round_num} è½®\n\n"
        md += f"### ğŸ‘· Builder æ–¹æ¡ˆ\n{r.builder_response}\n\n"
        md += f"### ğŸ•µï¸ Critic è¯„å®¡\n"
        md += f"- ç»¼åˆè¯„åˆ†: {r.scores.overall}/10\n"
        md += f"- é‡è¦æ€§: {r.scores.novelty}/10\n"
        md += f"- ä¸¥è°¨æ€§: {r.scores.soundness}/10\n"
        md += f"- åˆ›æ–°æ€§: {r.scores.significance}/10\n"
        md += f"- å®éªŒè®¾è®¡: {r.scores.experiments}/10\n"
        if r.scores.key_issues:
            md += f"- å…³é”®é—®é¢˜: {', '.join(r.scores.key_issues)}\n"
        md += f"\n---\n\n"
    
    return md

# ==========================================
# ä¾§è¾¹æ é…ç½®
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ è¾©è®ºé…ç½®")
    
    st.subheader("ğŸ¤– æ¨¡å‹é€‰æ‹©")
    builder_model = st.text_input(
        "Builder (æ–¹æ¡ˆè®¾è®¡)", 
        value=settings.AGENT_MODEL_NAME,
        help="æ¨èä½¿ç”¨ DeepSeek-R1"
    )
    critic_model = st.text_input(
        "Critic (æ–¹æ¡ˆå®¡æŸ¥)", 
        value=settings.CRITIC_MODEL_NAME,
        help="æ¨èä½¿ç”¨ Qwen-Max"
    )
    
    st.divider()
    
    st.subheader("ğŸšï¸ å‚æ•°è°ƒèŠ‚")
    max_rounds = st.slider("æœ€å¤§è½®æ¬¡", 3, 15, 8, help="é˜²æ­¢æ— é™è¾©è®º")
    builder_temp = st.slider("Builder åˆ›é€ æ€§", 0.0, 1.0, 0.7, 0.1)
    critic_temp = st.slider("Critic ä¸¥æ ¼åº¦", 0.0, 1.0, 0.3, 0.1, help="è¶Šä½è¶Šä¸¥æ ¼")
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºè¾©è®º", type="secondary"):
        st.session_state.clear()
        st.rerun()

# ==========================================
# Session State åˆå§‹åŒ–
# ==========================================
if "debate_rounds" not in st.session_state:
    st.session_state.debate_rounds: List[DebateRound] = []
if "is_running" not in st.session_state:
    st.session_state.is_running = False
if "current_goal" not in st.session_state:
    st.session_state.current_goal = ""

# ==========================================
# ä¸»ç•Œé¢
# ==========================================
st.subheader("1. è®¾å®šç ”ç©¶ç›®æ ‡")
user_goal = st.text_area(
    "æè¿°ä½ çš„ç ”ç©¶ç›®æ ‡æˆ–æŠ€æœ¯æƒ³æ³•",
    height=100,
    placeholder="ä¾‹å¦‚ï¼šè®¾è®¡ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„SQLæŸ¥è¯¢å®æ—¶ä¼˜åŒ–ç³»ç»Ÿï¼Œè¦æ±‚èƒ½å¤„ç†é«˜å¹¶å‘åœºæ™¯..."
)

col_start, col_status = st.columns([1, 3])
with col_start:
    start_btn = st.button(
        "ğŸš€ å¼€å§‹è¾©è®º", 
        type="primary", 
        disabled=st.session_state.is_running or not user_goal
    )
with col_status:
    if st.session_state.is_running:
        st.info("ğŸ”„ è¾©è®ºè¿›è¡Œä¸­...")
    elif st.session_state.debate_rounds:
        final = st.session_state.debate_rounds[-1]
        if final.scores.verdict == "PASS":
            st.success(f"âœ… è¾©è®ºå®Œæˆï¼æœ€ç»ˆè¯„åˆ†: {final.scores.overall}/10")
        else:
            st.warning(f"â¸ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œå½“å‰è¯„åˆ†: {final.scores.overall}/10")

st.divider()

# ==========================================
# è¾©è®ºæ‰§è¡Œé€»è¾‘
# ==========================================
if start_btn and user_goal:
    st.session_state.debate_rounds = []
    st.session_state.is_running = True
    st.session_state.current_goal = user_goal
    
    # åˆå§‹åŒ–æ¨¡å‹
    llm_builder = get_model_instance(builder_model, builder_temp)
    llm_critic = get_model_instance(critic_model, critic_temp)
    
    # åˆå§‹åŒ–å¯¹è¯å†å² - åŒæ–¹éƒ½ç»´æŠ¤å®Œæ•´å†å²
    builder_history = [SystemMessage(content=BUILDER_SYSTEM_PROMPT.format(goal=user_goal))]
    critic_history = [SystemMessage(content=CRITIC_SYSTEM_PROMPT)]
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # åˆ›å»ºå±•ç¤ºå®¹å™¨
    col_chat, col_stats = st.columns([2, 1])
    
    with col_stats:
        chart_placeholder = st.empty()
        stats_placeholder = st.empty()
    
    with col_chat:
        chat_container = st.container()
    
    try:
        for round_idx in range(1, max_rounds + 1):
            progress_bar.progress(round_idx / max_rounds)
            
            # === Builder å›åˆ ===
            status_text.text(f"ğŸ”„ ç¬¬ {round_idx} è½®: Builder æ­£åœ¨è®¾è®¡æ–¹æ¡ˆ...")
            
            with chat_container:
                with st.chat_message("assistant", avatar="ğŸ‘·"):
                    st.caption(f"**ç¬¬ {round_idx} è½® - Builder**")
                    builder_placeholder = st.empty()
                    builder_placeholder.text("æ€è€ƒä¸­...")
            
            builder_response = llm_builder.invoke(builder_history)
            builder_content = builder_response.content
            builder_history.append(AIMessage(content=builder_content))
            
            with chat_container:
                with st.chat_message("assistant", avatar="ğŸ‘·"):
                    st.caption(f"**ç¬¬ {round_idx} è½® - Builder**")
                    st.markdown(builder_content)
            
            time.sleep(0.5)
            
            # === Critic å›åˆ ===
            status_text.text(f"ğŸ”„ ç¬¬ {round_idx} è½®: Critic æ­£åœ¨å®¡æŸ¥...")
            
            # Critic çœ‹åˆ°å®Œæ•´è¾©è®ºå†å²
            critic_history.append(HumanMessage(
                content=f"## ç¬¬ {round_idx} è½® Builder æ–¹æ¡ˆ\n\n{builder_content}\n\nè¯·æŒ‰JSONæ ¼å¼è¯„ä¼°æ­¤æ–¹æ¡ˆã€‚"
            ))
            
            with chat_container:
                with st.chat_message("assistant", avatar="ğŸ•µï¸"):
                    st.caption(f"**ç¬¬ {round_idx} è½® - Critic**")
                    critic_placeholder = st.empty()
                    critic_placeholder.text("å®¡æŸ¥ä¸­...")
            
            critic_response = llm_critic.invoke(critic_history)
            critic_content = critic_response.content
            critic_history.append(AIMessage(content=critic_content))
            
            # è§£æè¯„åˆ†
            scores = parse_critic_response(critic_content)
            
            # è®°å½•æœ¬è½®ç»“æœ
            debate_round = DebateRound(
                round_num=round_idx,
                builder_response=builder_content,
                critic_response=critic_content,
                scores=scores,
                timestamp=time.time()
            )
            st.session_state.debate_rounds.append(debate_round)
            
            # å±•ç¤º Critic ç»“æœ
            with chat_container:
                with st.chat_message("assistant", avatar="ğŸ•µï¸"):
                    st.caption(f"**ç¬¬ {round_idx} è½® - Critic**")
                    
                    # è¯„åˆ†å¡ç‰‡
                    score_cols = st.columns(5)
                    score_cols[0].metric("ç»¼åˆ", f"{scores.overall}/10")
                    score_cols[1].metric("åˆ›æ–°æ€§", f"{scores.novelty}/10")
                    score_cols[2].metric("ä¸¥è°¨æ€§", f"{scores.soundness}/10")
                    score_cols[3].metric("é‡è¦æ€§", f"{scores.significance}/10")
                    score_cols[4].metric("å®éªŒ", f"{scores.experiments}/10")
                    
                    if scores.verdict == "PASS":
                        st.success("âœ… **PASS** - æ–¹æ¡ˆå·²é€šè¿‡å®¡æ ¸ï¼")
                    else:
                        if scores.key_issues:
                            st.warning("**å¾…æ”¹è¿›é—®é¢˜:**")
                            for issue in scores.key_issues:
                                st.markdown(f"- {issue}")
                        if scores.focus_next:
                            st.info(f"**ä¸‹è½®ç„¦ç‚¹:** {scores.focus_next}")
            
            # æ›´æ–°å›¾è¡¨
            with col_stats:
                fig = create_score_chart(st.session_state.debate_rounds)
                if fig:
                    chart_placeholder.plotly_chart(fig, use_container_width=True)
                
                # æ›´æ–°ç»Ÿè®¡
                stats_placeholder.markdown(f"""
                ### ğŸ“Š å½“å‰çŠ¶æ€
                - **è½®æ¬¡**: {round_idx}/{max_rounds}
                - **è¯„åˆ†**: {scores.overall}/10
                - **çŠ¶æ€**: {"ğŸŸ¢ é€šè¿‡" if scores.verdict == "PASS" else "ğŸŸ¡ ä¿®è®¢ä¸­"}
                """)
            
            # æ£€æŸ¥æ˜¯å¦é€šè¿‡
            if scores.verdict == "PASS" and scores.overall >= 8:
                status_text.text("ğŸ‰ è¾©è®ºæ”¶æ•›ï¼Œæ–¹æ¡ˆé€šè¿‡ï¼")
                st.balloons()
                break
            
            # å°† Critic åé¦ˆç»™ Builder
            feedback = f"""
## Critic è¯„å®¡ç»“æœ (ç¬¬ {round_idx} è½®)
- ç»¼åˆè¯„åˆ†: {scores.overall}/10
- å…³é”®é—®é¢˜: {', '.join(scores.key_issues) if scores.key_issues else 'æ— '}
- æ”¹è¿›ç„¦ç‚¹: {scores.focus_next}

è¯·é’ˆå¯¹ä»¥ä¸Šé—®é¢˜æ”¹è¿›ä½ çš„æ–¹æ¡ˆã€‚
"""
            builder_history.append(HumanMessage(content=feedback))
            
            time.sleep(0.5)
        
        else:
            status_text.text(f"âš ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡ ({max_rounds})ï¼Œè¾©è®ºç»“æŸ")
        
        progress_bar.empty()
        
    except Exception as e:
        st.error(f"âŒ è¾©è®ºè¿‡ç¨‹å‡ºé”™: {str(e)}")
    finally:
        st.session_state.is_running = False

# ==========================================
# å±•ç¤ºå†å²è®°å½• (éè¿è¡ŒçŠ¶æ€)
# ==========================================
if st.session_state.debate_rounds and not st.session_state.is_running:
    st.subheader("2. è¾©è®ºè¿›ç¨‹")
    
    col_history, col_analysis = st.columns([2, 1])
    
    with col_analysis:
        # è¯„åˆ†è¶‹åŠ¿å›¾
        fig = create_score_chart(st.session_state.debate_rounds)
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        
        # è¾©è®ºæ€»ç»“
        summary = generate_summary(
            st.session_state.debate_rounds,
            st.session_state.current_goal
        )
        st.markdown(summary)
        
        # å¯¼å‡ºæŒ‰é’®
        md_content = export_to_markdown(
            st.session_state.debate_rounds,
            st.session_state.current_goal
        )
        st.download_button(
            "ğŸ“¥ å¯¼å‡º Markdown",
            data=md_content,
            file_name="debate_record.md",
            mime="text/markdown"
        )
    
    with col_history:
        # è§’è‰²ç­›é€‰
        filter_role = st.radio(
            "ç­›é€‰è§’è‰²",
            ["å…¨éƒ¨", "åªçœ‹ Builder", "åªçœ‹ Critic"],
            horizontal=True
        )
        
        for r in st.session_state.debate_rounds:
            with st.expander(f"ğŸ“ ç¬¬ {r.round_num} è½® (è¯„åˆ†: {r.scores.overall}/10)", expanded=(r.round_num == len(st.session_state.debate_rounds))):
                if filter_role in ["å…¨éƒ¨", "åªçœ‹ Builder"]:
                    st.markdown("#### ğŸ‘· Builder")
                    st.markdown(r.builder_response)
                
                if filter_role in ["å…¨éƒ¨", "åªçœ‹ Critic"]:
                    st.markdown("#### ğŸ•µï¸ Critic")
                    score_cols = st.columns(5)
                    score_cols[0].metric("ç»¼åˆ", f"{r.scores.overall}/10")
                    score_cols[1].metric("åˆ›æ–°æ€§", f"{r.scores.novelty}/10")
                    score_cols[2].metric("ä¸¥è°¨æ€§", f"{r.scores.soundness}/10")
                    score_cols[3].metric("é‡è¦æ€§", f"{r.scores.significance}/10")
                    score_cols[4].metric("å®éªŒ", f"{r.scores.experiments}/10")
                    
                    if r.scores.key_issues:
                        st.warning("**é—®é¢˜:** " + ", ".join(r.scores.key_issues))
                    if r.scores.focus_next:
                        st.info(f"**ä¸‹è½®ç„¦ç‚¹:** {r.scores.focus_next}")