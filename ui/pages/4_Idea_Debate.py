import streamlit as st
import time
from typing import List, Dict
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

# --- å¯¼å…¥æ ¸å¿ƒé…ç½®ä¸æ¨¡å‹æ¥å£ ---
from config.settings import settings
from core.llm import get_agent_llm, get_critic_llm 

# å…œåº•å¯¼å…¥
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    pass

st.set_page_config(page_title="Auto-Debate Arena", page_icon="âš”ï¸", layout="wide")

st.title("âš”ï¸ Autonomous Adversarial Debate")
st.caption("è§‚å¯Ÿè€…æ¨¡å¼ï¼šè®¾å®šåˆå§‹ç›®æ ‡ï¼Œçœ‹ç€ AI è‡ªå·±åµæ¶ç›´è‡³æ”¶æ•›ã€‚")

# ==========================================
# 0. è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½æ¨¡å‹è·¯ç”± (ä¿æŒä¸å˜)
# ==========================================
def get_model_instance(model_name: str, temperature: float):
    """æ ¹æ®åå­—è‡ªåŠ¨è·¯ç”± API (DeepSeek vs Qwen vs OpenAI)"""
    model_name_lower = model_name.lower()
    if "deepseek" in model_name_lower:
        llm = get_agent_llm(temperature=temperature)
        llm.model_name = model_name
        return llm
    elif "qwen" in model_name_lower:
        llm = get_critic_llm(temperature=temperature)
        llm.model_name = model_name
        llm.temperature = temperature 
        return llm
    else:
        return ChatOpenAI(
            model=model_name, 
            temperature=temperature, 
            api_key=settings.OPENAI_API_KEY if hasattr(settings, 'OPENAI_API_KEY') else None
        )

# ==========================================
# 1. ä¾§è¾¹æ é…ç½®
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ Arena Config")
    
    # æ¨¡å‹é…ç½®
    st.subheader("Duelists")
    builder_model = st.text_input("Builder (Proposer)", value=settings.AGENT_MODEL_NAME, help="DeepSeek-R1 æ¨è")
    critic_model = st.text_input("Critic (Reviewer)", value=settings.CRITIC_MODEL_NAME, help="Qwen3-Max æ¨è")
    
    st.divider()
    
    # å¾ªç¯æ§åˆ¶
    max_rounds = st.slider("Max Rounds", 3, 20, 8, help="é˜²æ­¢æ— é™äº‰åµ")
    sleep_time = st.slider("Pacing (seconds)", 0.0, 5.0, 1.0, help="å›åˆé—´éš”ï¼Œæ–¹ä¾¿é˜…è¯»")
    
    if st.button("ğŸ—‘ï¸ Reset Arena"):
        st.session_state.clear()
        st.rerun()

# ==========================================
# 2. çŠ¶æ€ç®¡ç†
# ==========================================
if "debate_history" not in st.session_state:
    st.session_state.debate_history = [] 
if "is_running" not in st.session_state:
    st.session_state.is_running = False

# ==========================================
# 3. æ ¸å¿ƒ Prompt
# ==========================================
def get_builder_system_prompt(goal: str):
    return f"""
    You are **AI-Builder**. Your goal is to design the ULTIMATE research/technical solution.
    
    ### ğŸ¯ CORE OBJECTIVE (FROZEN):
    "{goal}"
    
    ### Rules:
    1. If this is the first turn, propose a comprehensive plan.
    2. If you received criticism, REFINE your solution to address the flaws.
    3. DO NOT change the Core Objective.
    4. Be highly technical, precise, and logical.
    5. Please response with chinese.
    """

def get_critic_system_prompt():
    return """
    You are **AI-Critic**. Your job is to stress-test the Builder's proposal.
    
    ### Rules:
    1. Identify fatal logic gaps, feasibility issues, or security risks.
    2. Be harsh but fair. 
    3. **TERMINATION CONDITION**: If the proposal is flawless and meets all constraints effectively, output EXACTLY the word: "PASS".
    4. Otherwise, list 1-3 specific criticisms.
    5. Please response with chinese.
    """

# ==========================================
# 4. æ‰§è¡Œé€»è¾‘ (æ— çŠ¶æ€æœºï¼Œçº¯å¾ªç¯)
# ==========================================
def run_debate_loop(initial_goal: str):
    # å®¹å™¨å ä½ç¬¦ï¼Œç”¨äºåŠ¨æ€æ»šåŠ¨æ˜¾ç¤º
    chat_container = st.container()
    
    # åˆå§‹åŒ–å†å² (ä»…ç”¨äºæœ¬æ¬¡è¿è¡Œçš„ä¸Šä¸‹æ–‡æ„å»º)
    # æ³¨æ„ï¼šä¸ºäº†è®© Builder è®°å¾—ä¹‹å‰çš„äº‰è®ºï¼Œæˆ‘ä»¬éœ€è¦ç»´æŠ¤ä¸€ä¸ª messages åˆ—è¡¨
    messages_for_builder = [SystemMessage(content=get_builder_system_prompt(initial_goal))]
    
    llm_builder = get_model_instance(builder_model, 0.7)
    llm_critic = get_model_instance(critic_model, 0.5)
    
    for round_idx in range(1, max_rounds + 1):
        
        # --- A. Builder Turn ---
        with chat_container:
            with st.chat_message("assistant", avatar="ğŸ‘·"):
                st.write(f"**Round {round_idx}: Builder is thinking...**")
                
                # Builder çœ‹åˆ°çš„æ˜¯ï¼šç³»ç»ŸæŒ‡ä»¤ + ä¹‹å‰çš„å¯¹è¯å†å²
                response_a = llm_builder.invoke(messages_for_builder)
                content_a = response_a.content
                
                st.markdown(content_a)
                
                # æ›´æ–°å†å²
                st.session_state.debate_history.append({"role": "Builder", "round": round_idx, "content": content_a})
                messages_for_builder.append(AIMessage(content=content_a))
        
        time.sleep(sleep_time)
        
        # --- B. Critic Turn ---
        with chat_container:
            with st.chat_message("assistant", avatar="ğŸ•µï¸"):
                st.write(f"**Round {round_idx}: Critic is reviewing...**")
                
                # Critic åªéœ€è¦çœ‹åˆ° Builder æœ€æ–°çš„æ–¹æ¡ˆ (æˆ–è€…ä½ å¯ä»¥é€‰æ‹©ç»™å®ƒçœ‹å…¨éƒ¨ï¼Œä½†é€šå¸¸åªçœ‹æœ€æ–°çš„æ–¹æ¡ˆæ›´å®¹æ˜“èšç„¦)
                # è¿™é‡Œæˆ‘ä»¬æ„å»ºä¸€ä¸ªæ–°çš„ prompt ç»™ Critic
                critic_input = [
                    SystemMessage(content=get_critic_system_prompt()),
                    HumanMessage(content=f"Here is the Builder's latest proposal (Round {round_idx}):\n\n{content_a}\n\nEvaluate it.")
                ]
                
                response_b = llm_critic.invoke(critic_input)
                content_b = response_b.content
                
                # æ£€æŸ¥æ˜¯å¦é€šè¿‡
                is_pass = "PASS" in content_b or "pass" in content_b if len(content_b) < 50 else False
                
                if is_pass:
                    st.success("âœ… **PASS**: Critic has approved the proposal!")
                else:
                    st.markdown(content_b)
                
                # æ›´æ–°å†å²
                st.session_state.debate_history.append({"role": "Critic", "round": round_idx, "content": content_b})
                
                # å…³é”®ï¼šæŠŠ Critic çš„æ„è§åé¦ˆç»™ Builder
                messages_for_builder.append(HumanMessage(content=f"Critic's Feedback: {content_b}\n\nPlease refine the solution."))

        if is_pass:
            st.balloons()
            return # ç»“æŸå¾ªç¯

        time.sleep(sleep_time)
        st.divider() # è§†è§‰åˆ†å‰²çº¿

    st.warning(f"âš ï¸ Reached max rounds ({max_rounds}) without full consensus.")

# ==========================================
# 5. ä¸»ç•Œé¢
# ==========================================
st.info("ğŸ’¡ **Tip**: Enter a vague idea (e.g., 'A flying car') and watch them turn it into a concrete spec.")

user_goal = st.text_area("Initial Research Goal / Hypothesis", height=100, placeholder="e.g. I want to use Reinforcement Learning to optimize SQL queries in real-time...")

col1, col2 = st.columns([1, 5])
with col1:
    start_btn = st.button("ğŸš€ Ignite Debate", type="primary", disabled=st.session_state.is_running)

# å¦‚æœæœ‰å†å²è®°å½•ï¼Œå…ˆå±•ç¤ºå‡ºæ¥ (ä¿è¯åˆ·æ–°åä¸æ¶ˆå¤±)
if st.session_state.debate_history and not start_btn:
    for item in st.session_state.debate_history:
        avatar = "ğŸ‘·" if item["role"] == "Builder" else "ğŸ•µï¸"
        with st.chat_message("assistant", avatar=avatar):
            st.caption(f"Round {item['round']} - {item['role']}")
            if item["content"] == "PASS":
                 st.success("âœ… PASS")
            else:
                 st.markdown(item["content"])

# ç‚¹å‡»å¼€å§‹å
if start_btn and user_goal:
    # æ¸…ç©ºæ—§å†å²
    st.session_state.debate_history = []
    st.session_state.is_running = True
    
    # è¿è¡Œå¾ªç¯
    try:
        run_debate_loop(user_goal)
    except Exception as e:
        st.error(f"âŒ Error detected: {e}")
    finally:
        st.session_state.is_running = False